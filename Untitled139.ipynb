{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled139.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNd/hVNSpzvlVGN5fgq2EyO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hamza1122/ML-Assignment--2/blob/main/Untitled139.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJp4lDKruRYw"
      },
      "source": [
        "#Importing libraries\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn import preprocessing\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aE-s2TcEux9O"
      },
      "source": [
        "# reading california hosuing dataset \n",
        "cal_housing = fetch_california_housing()\n",
        "df = pd.DataFrame(cal_housing.data, columns=cal_housing.feature_names)     #readinig all features\n",
        "y = cal_housing.target      #putting target values into the y variable\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEB7ZkfIuUYE"
      },
      "source": [
        "def kfold_cross(X,y):\n",
        "    cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "    return cv\n",
        "\n",
        "def train_test(X,y):\n",
        "  \"\"\"\n",
        "  A train_test function is splitting \n",
        "  the datasetinto train \n",
        "  and testing data.\n",
        "  A training data containg the 67% of original data\n",
        "  while testing data containing 33% of original data \n",
        "  \"\"\"\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "  return X_train,X_test,y_train,y_test\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def MultiLayer_Regressor(df,y):\n",
        "    \"\"\"\n",
        "    \n",
        "    Passing all features and target \n",
        "    values are passing \n",
        "    as a parameters in a function\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    total_score=[]\n",
        "    df['target']=y            # combining the target values in a dataframe\n",
        "   \n",
        "    y=df.target\n",
        "    X=df.drop(['target'],axis=1)           \n",
        "   \n",
        "    kf=kfold_cross(X,y)          #calling train_test func() to split the original data into train test.\n",
        "    \n",
        "    #After splitting it, we are passing training and testing data into MLP Regressor Alogorithm\n",
        "    regr = MLPRegressor(max_iter=200,solver='adam',learning_rate='adaptive',\n",
        "                    learning_rate_init=0.001, hidden_layer_sizes=(200,)  \n",
        "                    )          # A model with different parameters like learning_rate, optimizer, neurons_size\n",
        "    \n",
        "    for train_indices, test_indices in kf.split(X):\n",
        "\n",
        "        regr.fit(X.iloc[train_indices], y[train_indices])\n",
        "        kfold_score=regr.score(X.iloc[test_indices], y[test_indices])\n",
        "        total_score.append(kfold_score)\n",
        " \n",
        "   # total_score = regr.score(X_test, y_test)         #we are calculating the score on test data predicting by algorithm  \n",
        "    \n",
        "    \n",
        "    return total_score\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVvRa2AruezN"
      },
      "source": [
        "def label_encoder(data):\n",
        "  \"\"\"\n",
        "  Converting our categories to encoding like\n",
        "  A : 0, B : 1, C: 2, D : 3\n",
        "  We can't directly pass categorical values that's \n",
        "  why we are converting them into label encoding.\n",
        "  \"\"\"\n",
        "  le = preprocessing.LabelEncoder()\n",
        "  df['House_Category']=le.fit_transform(df['House_Category'])    # tranforming the categories to a number like 0,1,2,3\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "def MultiLayer_Classifier(df):\n",
        "    \"\"\"  \n",
        "    We are defining the categories by ourself\n",
        "    For Example,there is feature HouseAge in a dataset\n",
        "    containing numeric feature 1-80.So we are categorizing them on \n",
        "    their range like 0-25:'A', 26-50: 'B', 51-75: 'C', 76-100: 'D' \n",
        "    \"\"\"\n",
        "\n",
        "    bins=[0,25,50,75,100]\n",
        "    group_names=['A','B','C','D']\n",
        "    \n",
        "    df['House_Category']=pd.cut(df['HouseAge'],bins,labels=group_names)  # we are defining the category column based on the houseAge range values\n",
        "    \n",
        "    print(df.head(10))      #displaying the homeCategories\n",
        "    \n",
        "    df=label_encoder(df)    # calling a function to convert them into lable_encoding \n",
        "\n",
        "    y=df['House_Category']\n",
        "    X=df.drop(['House_Category'],axis=1)\n",
        "\n",
        "\n",
        "    X_train,X_test,y_train,y_test=train_test(X,y)     # calling a traing_test funct() to split the dataset into train test\n",
        "\n",
        "    #After splitting it, we are pssing training and testing data into MLP Classifier Alogorithm\n",
        "    clf = MLPClassifier(max_iter=200, solver='lbfgs',hidden_layer_sizes=200,\n",
        "                    learning_rate_init=0.001, learning_rate='adaptive',\n",
        "                    ).fit(X_train, y_train)  # A model with different parameters like learning_rate, optimizer, neurons_size\n",
        "\n",
        "    total_score=clf.score(X_test, y_test) #we are calculating the score on test data predicting by algorithm  \n",
        "    return total_score\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCWPPwMkuZ0e"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f3El-MfuiaH",
        "outputId": "5825be56-5622-4ba7-e832-6a0cdb1aec4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        " print(MultiLayer_Regressor(df,y))   # We are calling the Multi Regressor Algorithm and below the score of regressor"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.5675618333294865, -0.10367885602483451, -0.4964408052394229, 0.29575797987075003, -5.968932253920654, 0.4602499729854087, 0.2965619745200091, -0.2338696033850658, 0.3736924218168699, 0.2256714429424086]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmqt1fMgygO5",
        "outputId": "f71fe5df-a159-4dc0-a3bd-9533db1c66d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.HouseAge.unique()        #values of HouseAge column, further we will categorize them for classifier like :'A', 26-50: 'B', 51-75: 'C', 76-100: 'D'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([41., 21., 52., 42., 50., 40., 49., 48., 51., 43.,  2., 46., 26.,\n",
              "       20., 17., 36., 19., 23., 38., 35., 10., 16., 27., 39., 31., 29.,\n",
              "       22., 37., 28., 34., 32., 47., 44., 30., 18., 45., 33., 24., 15.,\n",
              "       14., 13., 25.,  5., 12.,  6.,  8.,  9.,  7.,  3.,  4., 11.,  1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hInC4suutPt",
        "outputId": "025166f1-b7a7-45f9-c466-452e1b9685af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        " print(MultiLayer_Classifier(df))    # We are calling the MultiCLassifer Function and below is the House_category Data we did by ourself alongwith classifer score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   MedInc  HouseAge  AveRooms  ...  Longitude  target  House_Category\n",
            "0  8.3252      41.0  6.984127  ...    -122.23   4.526               B\n",
            "1  8.3014      21.0  6.238137  ...    -122.22   3.585               A\n",
            "2  7.2574      52.0  8.288136  ...    -122.24   3.521               C\n",
            "3  5.6431      52.0  5.817352  ...    -122.25   3.413               C\n",
            "4  3.8462      52.0  6.281853  ...    -122.25   3.422               C\n",
            "5  4.0368      52.0  4.761658  ...    -122.25   2.697               C\n",
            "6  3.6591      52.0  4.931907  ...    -122.25   2.992               C\n",
            "7  3.1200      52.0  4.797527  ...    -122.25   2.414               C\n",
            "8  2.0804      42.0  4.294118  ...    -122.26   2.267               B\n",
            "9  3.6912      52.0  4.970588  ...    -122.25   2.611               C\n",
            "\n",
            "[10 rows x 10 columns]\n",
            "0.5173223722842043\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e07dMJ4W1ehS"
      },
      "source": [
        "\n",
        "#   MLP Regressor\n",
        "\n",
        "| Max Iteration| Optimizer | Learning_rate| Learning_rate_init|hiddenLayers_neurons|Score (testdata)|\n",
        "| --- | --- | --- | --- | --- |--- |\n",
        "500|Adam|Adaptive|0.001 |100 |  0.51\n",
        "300|Adam|Adaptive|0.001 |200 |  0.59\n",
        "100|Adam|Adaptive|0.0001|300 |  0.55\n",
        "200|Adam|Adaptive|0.001 |200 |  0.48\n",
        "500|sgd |Adaptive|0.00|100 | -1.10\n",
        "100|sgd |Adaptive|0.0001 |300 |-6.16\n",
        "300|sgd |Adaptive|0.001 |200|-4.25\n",
        "200|sgd |Adaptive|0.001 |200|-6.01\n",
        "500|lbfgs| Adaptive |0.001|100|0.53\n",
        "100|lbfgs|Adaptive |0.0001|300|0.32\n",
        "300|lbfgs|Adaptive|0.001|200|0.51\n",
        "200|lbfgs|Adaptive|0.001|200|0.52\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUbAqm965Axi"
      },
      "source": [
        "\n",
        "#   MLP Classifier\n",
        "\n",
        "| Max Iteration| Optimizer | Learning_rate| Learning_rate_init|hiddenLayers_neurons|Score (testdata)|\n",
        "| --- | --- | --- | --- | --- |--- |\n",
        "  500   |          Adam    |   Adaptive     |           0.001                 |100      |               0.92\n",
        "  300     |        Adam     |  Adaptive    |            0.001                 |200        |             0.95\n",
        "  100       |      Adam     |  Adaptive   |             0.0001                |300          |           0.96\n",
        "  200         |    Adam      | Adaptive  |              0.001                 |200            |         0.98\n",
        "500  |           sgd    |   Adaptive    |            0.001                 |100    |                  0.52\n",
        "  300   |          sgd    |   Adaptive  |              0.001                 |200      |                0.95\n",
        "  100     |        sgd     |  Adaptive |               0.0001                |300        |              0.97\n",
        "  200       |      sgd      | Adaptive|                0.001                 |200          |            0.53\n",
        "500    |         lbfgs     |  Adaptive |               0.001                 |100       |              0.41\n",
        "  300      |       lbfgs    |   Adaptive  |              0.001                 |200        |             0.33\n",
        "  100       |      lbfgs   |    Adaptive   |             0.0001                |300          |           0.51\n",
        "  200         |    lbfgs  |     Adaptive    |            0.001                 |200            |         0.40\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej_TmUvowcC4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}